{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Improving the Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THIS ASSIGNMENT IS STILL WORK-IN-PROGRESS AND SUBJECT TO CHANGE!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will improve the search index and query functions from the previous assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Defining Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is copied from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2, re\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "from IPython.display import display, HTML\n",
    "from math import log10, sqrt\n",
    "\n",
    "Summaries_file = 'data/aspirin__Summaries.pkl.bz2'\n",
    "Abstracts_file = 'data/aspirin__Abstracts.pkl.bz2'\n",
    "\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
    "    \"\"\"\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/%s>%s</a>' % (s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>%s</em></small>' % Abstracts[id])\n",
    "    if (show_id):\n",
    "        lines.append('[ID: %d]' % id)\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for (id, abstract) in Abstracts.items():\n",
    "    for term in preprocess(tokenize(abstract)):\n",
    "        inverted_index[term].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see from the results of the last assignment, our simple index doesn't handle punctuation and the difference between singular and plural versions of the same word very well. Fortunately, Python's _NLTK_ package provides implementations of these algorithms we can use. If your Python package doesn't already come with it, you have to install _NLTK_ by following [these instructions](http://www.nltk.org/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "['Good', 'muffins', 'cost', '$3.88\\nin', 'New', 'York.', '', 'Please', 'buy', 'me', 'two', 'of', 'them.\\n\\nThanks.']\n",
      "['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
    "\n",
    "print(tokenize(s))\n",
    "print(word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"processes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to improve our search results is to *rank* them. A possible way to do this is to calculate a score for each document based on the matching terms from the query. One such scoring method is *tf-idf*, which comes with several variants, as explained in the lecture slides.\n",
    "\n",
    "In order to quickly calculate the scores for a term/document combination, we'll need quick access to a couple of things:\n",
    "\n",
    "- tf(t,d): How often does a term occur in a document\n",
    "- df(t): In how many documents does a term occur\n",
    "- length_tf(d): The length of the document vector (with vectors of plain tf values)\n",
    "- num_documents: The number of documents in our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = defaultdict(Counter)\n",
    "length_values = defaultdict(int)\n",
    "\n",
    "for (doc_id, abstract) in Abstracts.items():\n",
    "    tokens = preprocess(tokenize(abstract))\n",
    "    tf_matrix[doc_id] = Counter(tokens)\n",
    "    l = 0\n",
    "    for t in tf_matrix[doc_id].keys():\n",
    "        l += tf_matrix[doc_id][t] ** 2\n",
    "    length_values[doc_id] = sqrt(l)\n",
    "\n",
    "def tf(t,d):\n",
    "    return float(tf_matrix[d][t])\n",
    "\n",
    "def df(t):\n",
    "    return float(len(inverted_index[t]))\n",
    "\n",
    "def length_tf(d):\n",
    "    return length_values[d]\n",
    "\n",
    "num_documents = float(len(Abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test these functions with some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "105.0\n",
      "13.92838827718412\n",
      "43542.0\n"
     ]
    }
   ],
   "source": [
    "print(tf('network', 22148098))\n",
    "print(df('network'))\n",
    "print(length_tf(22148098))\n",
    "print(num_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these three helper functions, we can now easily calculate the _tf-idf_ weights of a term in a document by implementing the weighting formula from the slides, which you will do in the assignments below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement in the code block below the `smarter_tokenize` function using NLTK's function for tokenization, and the `smarter_preprocess` function to perform stemming in addition to case normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smarter linguistic processing\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "#def smarter_tokenize(text):\n",
    "#  ...\n",
    "\n",
    "#def smarter_preprocess(tokens):\n",
    "#  ...\n",
    "\n",
    "# To test it:\n",
    "print(smarter_preprocess(smarter_tokenize(\"He buys many books, some about I.R., for less than $1.50!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a smarter index based on these functions. For practical purposes, the code below generates the smarter index on a subset of the data, as generating an index with stemming on the entire set would take too much time. (You don't need to change or add anything in the code block below. Just leave it as it is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we create our smarter index (based on a subset of the documents for demonstration purposes)\n",
    "smarter_index = defaultdict(set)\n",
    "\n",
    "# Here we define the subset (somewhat arbitrary):\n",
    "subset_of_ids = set(key for key in Abstracts.keys() if 28700000 <= key < 28800000)\n",
    "subset_of_abstracts = ((key, Abstracts[key]) for key in subset_of_ids)\n",
    "\n",
    "# Uncomment this line to process the whole corpus (might take a long time):\n",
    "#subset_of_abstracts = Abstracts.items()\n",
    "\n",
    "# Building our smarter index:\n",
    "for (id, abstract) in subset_of_abstracts:\n",
    "    for term in smarter_preprocess(smarter_tokenize(abstract)):\n",
    "        smarter_index[term].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the `smarter_and_query` function based on the two functions `smarter_tokenize` and `smarter_preprocess` you defined above. You can start from the code for `and_query` from the last assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smarter and_query based on the smarter tokenize and preprocess functions\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "#def smarter_and_query(query_string):\n",
    "#  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Run the queries \"moringa seed extracts\" and \"gstp1\" with the new `smarter_and_query` function from task 1. Do they return paper *28792522* (this is our exemplary paper from the last assignment)? For each of the two example queries, what do our new smarter functions specifically contribute to the result (as compared to our previous naive implementations for tokenization and preprocessing)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** [Write your answer text here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Now we move to a different subject and use our old index again. That is, we **don't** use the smarter functions defined above for tasks 3 to 5!\n",
    "\n",
    "Create a function `tfidf(t,d)` that returns the tf-idf score of term `t` in document `d` by using `tf(t,d)`, `df(t)` and `num_documents` as defined above. The tf-idf formula can be found on the lecture slides. Use tf-idf with plain (non-logarithmic) term frequency, as applied by scoring variant `ntn`. Test your function with the examples shown below. You can use the `log10(n)` function to calculate the base 10 logarithm.\n",
    "\n",
    "Again, use our old (non-smart) index for this task and the tasks below, and **not** the functions defined in tasks 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tfidf(t,d):\n",
    "#    ...\n",
    "\n",
    "#print(tfidf('network', 24130474))\n",
    "#print(tfidf('var', 24130474))\n",
    "#print(tfidf('surface', 24130474))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Create a function `query_ntn(query_string)`, which accepts as input a single query string that could consist of one or more words, and returns or prints a list of (up to) 10 best matching documents, along with their score. Use _tf-idf_ to calculate document scores based on the query, applying variant `ntn`, as above (see the formula for the `ntn` version of scoring on the lecture slides). Use an auxiliary function `score_ntn` to calculate the score. The results should be shown in descending order by score.\n",
    "\n",
    "You can start by copying your `or_query` function from assignment 2, then expand that to rank the results, making use of the `tfidf(t,d)` function you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_ntn(query_words, doc_id)\n",
    "#    ...\n",
    "\n",
    "#query_ntn(query_string)\n",
    "#    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Create a second version of the query function from Task 4, and call it `query_nnc`. This second version should use, as its name suggests, variant `nnc` instead of `ntn`, and therefore apply the cosine similarity measure. (See the formula for `score_nnc` on the lecture slides. You can drop the square root of |q| in the formula, as indicated on the slides.) You can use the `length_tf` function defined above. Use again an auxiliary function called `score_nnc`. You can start by copy-pasting the code from Task 4.\n",
    "\n",
    "Use the provided `display_summary` function to make the output a bit more like the results page of a search engine, and demonstrate your `query_nnc` function with two or three interesting example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_nnc(query_words, doc_id)\n",
    "#    ...\n",
    "\n",
    "#query_nnc(query_string)\n",
    "#    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
