{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset of research papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) module, a part of the [Biopython](http://biopython.org/) library, will be used to interface with [PubMed](http://www.ncbi.nlm.nih.gov/pubmed).<br>\n",
    "You can download Biopython from [here](http://biopython.org/wiki/Download).\n",
    "\n",
    "In this notebook we will be covering several of the steps taken in the [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html), specifically in [Chapter 9  Accessing NCBIâ€™s Entrez databases](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "# NCBI requires you to set your email address to make use of NCBI's E-utilities\n",
    "Entrez.email = \"Your.Name.Here@example.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets will be saved as serialized Python objects, compressed with bzip2.\n",
    "Saving/loading them will therefore require the [pickle](http://docs.python.org/3/library/pickle.html) and [bz2](http://docs.python.org/3/library/bz2.html) modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle, bz2, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EInfo: Obtaining information about the Entrez databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accessing extended information about the PubMed database\n",
    "pubmed = Entrez.read( Entrez.einfo(db=\"pubmed\"), validate=False )[u'DbInfo']\n",
    "\n",
    "# list of possible search fields for use with ESearch:\n",
    "search_fields = { f['Name']:f['Description'] for f in pubmed[\"FieldList\"] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In search_fields, we find 'TIAB' ('Free text associated with Abstract/Title') as a possible search field to use in searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFFL': \"Author's institutional affiliation and address\",\n",
       " 'ALL': 'All terms from all searchable fields',\n",
       " 'AUCL': 'Author Cluster ID',\n",
       " 'AUID': 'Author Identifier',\n",
       " 'AUTH': 'Author(s) of publication',\n",
       " 'BOOK': 'ID of the book that contains the document',\n",
       " 'CDAT': 'Date of completion',\n",
       " 'CNTY': 'Country of publication',\n",
       " 'COIS': 'Conflict of Interest Statements',\n",
       " 'COLN': 'Corporate Author of publication',\n",
       " 'CRDT': 'Date publication first accessible through Entrez',\n",
       " 'DSO': 'Additional text from the summary',\n",
       " 'ECNO': 'EC number for enzyme or CAS registry number',\n",
       " 'ED': \"Section's Editor\",\n",
       " 'EDAT': 'Date publication first accessible through Entrez',\n",
       " 'EID': 'Extended PMID',\n",
       " 'EPDT': 'Date of Electronic publication',\n",
       " 'FAUT': 'First Author of publication',\n",
       " 'FILT': 'Limits the records',\n",
       " 'FINV': 'Full name of investigator',\n",
       " 'FULL': 'Full Author Name(s) of publication',\n",
       " 'GRNT': 'NIH Grant Numbers',\n",
       " 'INVR': 'Investigator',\n",
       " 'ISBN': 'ISBN',\n",
       " 'ISS': 'Issue number of publication',\n",
       " 'JOUR': 'Journal abbreviation of publication',\n",
       " 'LANG': 'Language of publication',\n",
       " 'LAUT': 'Last Author of publication',\n",
       " 'LID': 'ELocation ID',\n",
       " 'MAJR': 'MeSH terms of major importance to publication',\n",
       " 'MDAT': 'Date of last modification',\n",
       " 'MESH': 'Medical Subject Headings assigned to publication',\n",
       " 'MHDA': 'Date publication was indexed with MeSH terms',\n",
       " 'OTRM': 'Other terms associated with publication',\n",
       " 'PAGE': 'Page number(s) of publication',\n",
       " 'PAPX': 'MeSH pharmacological action pre-explosions',\n",
       " 'PDAT': 'Date of publication',\n",
       " 'PID': 'Publisher ID',\n",
       " 'PPDT': 'Date of print publication',\n",
       " 'PS': 'Personal Name as Subject',\n",
       " 'PTYP': 'Type of publication (e.g., review)',\n",
       " 'PUBN': \"Publisher's name\",\n",
       " 'SI': 'Cross-reference from publication to other databases',\n",
       " 'SUBH': 'Additional specificity for MeSH term',\n",
       " 'SUBS': 'CAS chemical name or MEDLINE Substance Name',\n",
       " 'TIAB': 'Free text associated with Abstract/Title',\n",
       " 'TITL': 'Words in title of publication',\n",
       " 'TT': 'Words in transliterated title of publication',\n",
       " 'UID': 'Unique number assigned to publication',\n",
       " 'VOL': 'Volume number of publication',\n",
       " 'WORD': 'Free text associated with publication'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESearch: Searching the Entrez databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the kind of data we get when searching the database, we'll perform a search for papers authored by Haasdijk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranslationSet': [], 'QueryTranslation': 'Haasdijk E[Author]', 'TranslationStack': [{'Explode': 'N', 'Field': 'Author', 'Term': 'Haasdijk E[Author]', 'Count': '35'}, 'GROUP'], 'RetStart': '0', 'RetMax': '20', 'IdList': ['28513205', '28513201', '28323435', '28140628', '26933487', '24977986', '24901702', '24852945', '24708899', '24252306', '23580075', '23144668', '22174697', '22154920', '21870131', '21760539', '20662596', '20602234', '20386726', '18579581'], 'Count': '35'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_authors = ['Haasdijk E']\n",
    "example_search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=' AND '.join([a+'[AUTH]' for a in example_authors]) ) )\n",
    "example_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the result being produced is not in Python's native string format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Entrez.Parser.StringElement"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( example_search['IdList'][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part of the query's result we are most interested in is accessible through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28513205, 28513201, 28323435, 28140628, 26933487, 24977986, 24901702, 24852945, 24708899, 24252306, 23580075, 23144668, 22174697, 22154920, 21870131, 21760539, 20662596, 20602234, 20386726, 18579581]\n"
     ]
    }
   ],
   "source": [
    "example_ids = [ int(id) for id in example_search['IdList'] ]\n",
    "print(example_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed IDs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now assemble a dataset comprised of research articles containing the keyword \"evolution\", in either their titles or abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_term = 'aspirin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ids_file = 'data/' + search_term + '__Ids.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching IDs of results [0,10000]\n",
      "Fetching IDs of results [10000,20000]\n",
      "Fetching IDs of results [20000,30000]\n",
      "Fetching IDs of results [30000,40000]\n",
      "Fetching IDs of results [40000,50000]\n",
      "43593 documents contain the search term \"aspirin\".\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists( Ids_file ):\n",
    "    Ids = pickle.load( bz2.BZ2File( Ids_file, 'rb' ) )\n",
    "else:\n",
    "    # determine the number of hits for the search term\n",
    "    search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retmax=0 ) )\n",
    "    total = int( search['Count'] )\n",
    "    \n",
    "    # `Ids` will be incrementally assembled, by performing multiple queries,\n",
    "    # each returning at most `retrieve_per_query` entries.\n",
    "    Ids_str = []\n",
    "    retrieve_per_query = 10000\n",
    "    \n",
    "    for start in range( 0, total, retrieve_per_query ):\n",
    "        print('Fetching IDs of results [%d,%d]' % ( start, start+retrieve_per_query ) )\n",
    "        s = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retstart=start, retmax=retrieve_per_query ) )\n",
    "        Ids_str.extend( s[ u'IdList' ] )\n",
    "    \n",
    "    # convert Ids to integers (and ensure that the conversion is reversible)\n",
    "    Ids = [ int(id) for id in Ids_str ]\n",
    "    \n",
    "    for (id_str, id_int) in zip(Ids_str, Ids):\n",
    "        if str(id_int) != id_str:\n",
    "            raise Exception('Conversion of PubMed ID %s from string to integer it not reversible.' % id_str )\n",
    "    \n",
    "    # Remove IDs that would cause problems below:\n",
    "    Ids.remove(28334544)\n",
    "    \n",
    "    # Save list of Ids\n",
    "    pickle.dump( Ids, bz2.BZ2File( Ids_file, 'wb' ) )\n",
    "    \n",
    "total = len( Ids )\n",
    "print('%d documents contain the search term \"%s\".' % ( total, search_term ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at what we just retrieved, here are the last 5 elements of the `Ids` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28981968, 28981961, 28978235, 28978007, 28976678]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESummary: Retrieving summaries from primary IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the kind of metadata we get from a call to `Entrez.esummary()`, we now fetch the summary of one of Haasdijk's papers (using one of the PubMed IDs we obtained in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HasAbstract\n",
      "\t 1\n",
      "PubDate\n",
      "\t 1998 Nov\n",
      "LastAuthor\n",
      "\t Domschke W\n",
      "DOI\n",
      "\t 10.1111/j.1440-1746.1998.tb01876.x\n",
      "ELocationID\n",
      "\t doi: 10.1111/j.1440-1746.1998.tb01876.x\n",
      "ISSN\n",
      "\t 0815-9319\n",
      "FullJournalName\n",
      "\t Journal of gastroenterology and hepatology\n",
      "References\n",
      "\t []\n",
      "Volume\n",
      "\t 13\n",
      "Source\n",
      "\t J Gastroenterol Hepatol\n",
      "Title\n",
      "\t Gastric adaptation to aspirin and Helicobacter pylori infection in man.\n",
      "Id\n",
      "\t 28976678\n",
      "PubStatus\n",
      "\t ppublish\n",
      "RecordStatus\n",
      "\t PubMed\n",
      "PmcRefCount\n",
      "\t 0\n",
      "ESSN\n",
      "\t 1440-1746\n",
      "Item\n",
      "\t []\n",
      "NlmUniqueID\n",
      "\t 8607909\n",
      "PubTypeList\n",
      "\t ['Journal Article']\n",
      "History\n",
      "\t {'pubmed': ['1998/11/01 00:00'], 'entrez': '2017/10/05 06:00', 'medline': ['1998/11/01 00:01']}\n",
      "SO\n",
      "\t 1998 Nov;13(S3):S193-S198\n",
      "LangList\n",
      "\t ['English']\n",
      "Issue\n",
      "\t S3\n",
      "AuthorList\n",
      "\t ['Konturek J', 'Konturek S', 'Dembinski A', 'Domschke W']\n",
      "ArticleIds\n",
      "\t {'pubmed': ['28976678'], 'rid': '28976678', 'doi': '10.1111/j.1440-1746.1998.tb01876.x', 'eid': '28976678', 'medline': []}\n",
      "EPubDate\n",
      "\t \n",
      "Pages\n",
      "\t S193-S198\n"
     ]
    }
   ],
   "source": [
    "example_paper = Entrez.read( Entrez.esummary(db=\"pubmed\", id='28976678') )[0]\n",
    "\n",
    "def print_dict( p ):\n",
    "    for k,v in p.items():\n",
    "        print(k)\n",
    "        print('\\t', v)\n",
    "\n",
    "print_dict(example_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll keep just some basic information for each paper: title, list of authors, publication year, and [DOI](https://en.wikipedia.org/wiki/Digital_object_identifier).\n",
    "\n",
    "In case you are not familiar with the DOI system, know that the paper above can be accessed through the link [http://dx.doi.org/10.1007/s12065-012-0071-x](http://dx.doi.org/10.1007/s12065-012-0071-x) (which is `http://dx.doi.org/` followed by the paper's DOI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gastric adaptation to aspirin and Helicobacter pylori infection in man.',\n",
       " ['Konturek J', 'Konturek S', 'Dembinski A', 'Domschke W'],\n",
       " 1998,\n",
       " '10.1111/j.1440-1746.1998.tb01876.x')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( example_paper['Title'], example_paper['AuthorList'], int(example_paper['PubDate'][:4]), example_paper['DOI'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to assemble a dataset containing the summaries of all the paper `Ids` we previously fetched.\n",
    "\n",
    "To reduce the memory footprint, and to ensure the saved datasets won't depend on Biopython being installed to be properly loaded, values returned by `Entrez.read()` will be converted to their corresponding native Python types. We start by defining a function for helping with the conversion of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Summaries_file = 'data/' + search_term + '__Summaries.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Summaries of results: \n",
      "\n",
      "0...................\n",
      "10000...................\n",
      "20000...................\n",
      "30000...................\n",
      "40000......."
     ]
    }
   ],
   "source": [
    "if os.path.exists( Summaries_file ):\n",
    "    Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "else:\n",
    "    # `Summaries` will be incrementally assembled, by performing multiple queries,\n",
    "    # each returning at most `retrieve_per_query` entries.\n",
    "    Summaries = []\n",
    "    retrieve_per_query = 500\n",
    "    \n",
    "    print('Fetching Summaries of results: ')\n",
    "    for start in range( 0, len(Ids), retrieve_per_query ):\n",
    "        if (start % 10000 == 0):\n",
    "            print('')\n",
    "            print(start, end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        \n",
    "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
    "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
    "        \n",
    "        s = Entrez.read( Entrez.esummary( db=\"pubmed\", id=query_ids ) )\n",
    "        \n",
    "        # out of the retrieved data, we will keep only a tuple (title, authors, year, DOI), associated with the paper's id.\n",
    "        # (all values converted to native Python formats)\n",
    "        for p in s:\n",
    "            try:\n",
    "                f = [\n",
    "                    ( int( p['Id'] ), (\n",
    "                        str( p['Title'] ),\n",
    "                        [ str(a) for a in p['AuthorList'] ],\n",
    "                        int( p['PubDate'][:4] ),                # keeps just the publication year\n",
    "                        str( p.get('DOI', '') )            # papers for which no DOI is available get an empty string in their place\n",
    "                        ) )\n",
    "                    ]\n",
    "                Summaries.extend( f )\n",
    "            except ValueError as e:\n",
    "                print(\"\\nError with ID \" + p['Id'] + \": \" + str(e))\n",
    "                print(\"Manually remove this ID above and re-run code.\")\n",
    "    \n",
    "    # Save Summaries, as a dictionary indexed by Ids\n",
    "    Summaries = dict( Summaries )\n",
    "    \n",
    "    pickle.dump( Summaries, bz2.BZ2File( Summaries_file, 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the first 3 retrieved summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{28978235: ('The Effect of Monthly Medication on Mortality After a Coronary Event.',\n",
       "  ['Montero-Balosa MC', 'FernÃ¡ndez-Urrusuno R', 'Vilches-Arenas A'],\n",
       "  2017,\n",
       "  '10.1177/1074248417732833'),\n",
       " 28981961: ('Contemporary Use of Oral Antithrombotic Agents: Focus on Dual and Triple Therapeutic Approaches.',\n",
       "  ['Jenkins AT', 'Kantorovich A', 'Burman L'],\n",
       "  2017,\n",
       "  '10.1002/phar.2041'),\n",
       " 28981968: ('Omalizumab could be effective in children with severe eosinophilic non-allergic asthma.',\n",
       "  ['Bourgoin-Heck M',\n",
       "   'Amat F',\n",
       "   'TrouvÃ© C',\n",
       "   'Bernard A',\n",
       "   'Magny JP',\n",
       "   'Lambert N',\n",
       "   'Just J'],\n",
       "  2017,\n",
       "  '10.1111/pai.12813')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ id : Summaries[id] for id in Ids[:3] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFetch: Downloading full records from Entrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Entrez.efetch()` is the function that will allow us to obtain paper abstracts. Let us start by taking a look at the kind of data it returns when we query PubMed's database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = Entrez.read( Entrez.efetch(db=\"pubmed\", id='28976678', retmode=\"xml\") )['PubmedArticle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`q` is a list, with each member corresponding to a queried id. Because here we only queried for one id, its results are then in `q[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q), len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\n",
    "At `q[0]` we find a dictionary containing two keys, the contents of which we print below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bio.Entrez.Parser.DictionaryElement,\n",
       " dict_keys(['PubmedData', 'MedlineCitation']))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q[0]), q[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticleIdList\n",
      "\t [StringElement('28976678', attributes={'IdType': 'pubmed'}), StringElement('10.1111/j.1440-1746.1998.tb01876.x', attributes={'IdType': 'doi'})]\n",
      "PublicationStatus\n",
      "\t ppublish\n",
      "History\n",
      "\t [DictElement({'Day': '5', 'Minute': '0', 'Year': '2017', 'Month': '10', 'Hour': '6'}, attributes={'PubStatus': 'entrez'}), DictElement({'Day': '1', 'Minute': '0', 'Year': '1998', 'Month': '11', 'Hour': '0'}, attributes={'PubStatus': 'pubmed'}), DictElement({'Day': '1', 'Minute': '1', 'Year': '1998', 'Month': '11', 'Hour': '0'}, attributes={'PubStatus': 'medline'})]\n"
     ]
    }
   ],
   "source": [
    "print_dict( q[0][ 'PubmedData' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key `'MedlineCitation'` maps into another dictionary. In that dictionary, most of the information is contained under the key `'Article'`. To minimize the clutter, below we show the contents of `'MedlineCitation'` excluding its `'Article'` member, and below that we then show the contents of `'Article'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceFlightMission\n",
      "\t []\n",
      "OtherAbstract\n",
      "\t []\n",
      "KeywordList\n",
      "\t [ListElement([StringElement('Helicobacter pylori', attributes={'MajorTopicYN': 'N'}), StringElement('adaptation', attributes={'MajorTopicYN': 'N'}), StringElement('aspirin', attributes={'MajorTopicYN': 'N'}), StringElement('epithelial cell proliferation', attributes={'MajorTopicYN': 'N'}), StringElement('gastric blood flow', attributes={'MajorTopicYN': 'N'}), StringElement('stomach', attributes={'MajorTopicYN': 'N'})], attributes={'Owner': 'NOTNLM'})]\n",
      "MedlineJournalInfo\n",
      "\t {'Country': 'Australia', 'NlmUniqueID': '8607909', 'MedlineTA': 'J Gastroenterol Hepatol', 'ISSNLinking': '0815-9319'}\n",
      "OtherID\n",
      "\t []\n",
      "DateRevised\n",
      "\t {'Day': '04', 'Year': '2017', 'Month': '10'}\n",
      "CitationSubset\n",
      "\t []\n",
      "PMID\n",
      "\t 28976678\n",
      "GeneralNote\n",
      "\t []\n",
      "DateCreated\n",
      "\t {'Day': '04', 'Year': '2017', 'Month': '10'}\n"
     ]
    }
   ],
   "source": [
    "print_dict( { k:v for k,v in q[0][ 'MedlineCitation' ].items() if k!='Article' } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticleTitle\n",
      "\t Gastric adaptation to aspirin and Helicobacter pylori infection in man.\n",
      "Pagination\n",
      "\t {'MedlinePgn': 'S193-S198'}\n",
      "PublicationTypeList\n",
      "\t [StringElement('Journal Article', attributes={'UI': 'D016428'})]\n",
      "Language\n",
      "\t ['eng']\n",
      "AuthorList\n",
      "\t ListElement([DictElement({'ForeName': 'Jan', 'LastName': 'Konturek', 'AffiliationInfo': [{'Affiliation': 'Department of Medicine B, University of MÃ¼nster, MÃ¼nster, GermanyInstitute of Physiology, and Pathomorphology, Jagiellonian University, Krakow, Poland.', 'Identifier': []}], 'Identifier': [], 'Initials': 'J'}, attributes={'ValidYN': 'Y'}), DictElement({'ForeName': 'Stanislaw', 'LastName': 'Konturek', 'AffiliationInfo': [{'Affiliation': 'Department of Medicine B, University of MÃ¼nster, MÃ¼nster, GermanyInstitute of Physiology, and Pathomorphology, Jagiellonian University, Krakow, Poland.', 'Identifier': []}], 'Identifier': [], 'Initials': 'S'}, attributes={'ValidYN': 'Y'}), DictElement({'ForeName': 'Artur', 'LastName': 'Dembinski', 'AffiliationInfo': [{'Affiliation': 'Department of Medicine B, University of MÃ¼nster, MÃ¼nster, GermanyInstitute of Physiology, and Pathomorphology, Jagiellonian University, Krakow, Poland.', 'Identifier': []}], 'Identifier': [], 'Initials': 'A'}, attributes={'ValidYN': 'Y'}), DictElement({'ForeName': 'Wolfram', 'LastName': 'Domschke', 'AffiliationInfo': [{'Affiliation': 'Department of Medicine B, University of MÃ¼nster, MÃ¼nster, GermanyInstitute of Physiology, and Pathomorphology, Jagiellonian University, Krakow, Poland.', 'Identifier': []}], 'Identifier': [], 'Initials': 'W'}, attributes={'ValidYN': 'Y'})], attributes={'CompleteYN': 'Y'})\n",
      "ArticleDate\n",
      "\t []\n",
      "ELocationID\n",
      "\t [StringElement('10.1111/j.1440-1746.1998.tb01876.x', attributes={'EIdType': 'doi', 'ValidYN': 'Y'})]\n",
      "Journal\n",
      "\t {'JournalIssue': DictElement({'Volume': '13', 'PubDate': {'Year': '1998', 'Month': 'Nov'}, 'Issue': 'S3'}, attributes={'CitedMedium': 'Internet'}), 'ISSN': StringElement('1440-1746', attributes={'IssnType': 'Electronic'}), 'Title': 'Journal of gastroenterology and hepatology', 'ISOAbbreviation': 'J. Gastroenterol. Hepatol.'}\n",
      "Abstract\n",
      "\t {'AbstractText': ['The relationship between Helicobacter pylori infection and aspirin (ASA)-induced gastropathy and gastric adaptation to ASA remains unclear. We compared gastric damage and adaptation after repeated exposures to ASA in the same subjects without H. pylori infection and those infected by H. pylori before and after eradication of this H. pylori. Twenty-four volunteers in two groups (A and B), without H. pylori infection (group A) and with H. pylori infection (group B) before and after H. pylori eradication, were given ASA 2 g/day or placebo for 14 days. Mucosal damage was evaluated by endoscopy and gastric microbleeding; mucosal prostaglandin (PG) E2 generation and luminal transforming growth factor (TGF)Î± were determined on days 0,3,7 and 14 of the ASA course. In all subjects, ASA-induced gastric damage reached a maximum on day 3. In H. pylori-positive subjects this damage was maintained at a similar level up to the 14th day of observation. Following H. pylori eradication, the damage was significantly lessened at day 14, as revealed by both endoscopy and microbleeding, and was accompanied by increased mucosal release of TGFÎ±. Prostaglandin E2 generation was significantly higher in H. pylori-positive subjects than after H. pylori eradication, but ASA treatment resulted in greater than 90% reduction of this generation independent of H. pylori status. Gastric adaptation to ASA is impaired in H. pylori-positive subjects but eradication of this bacterium restores this process.'], 'CopyrightInformation': 'Â© 1998 The Official Publication of the Asian Pacific Association for the Study of the Liver and the Asian Pacific Association of Gastroenterology.'}\n"
     ]
    }
   ],
   "source": [
    "print_dict( q[0][ 'MedlineCitation' ][ 'Article' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paper's abstract can therefore be accessed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{28976678: 'The relationship between Helicobacter pylori infection and aspirin (ASA)-induced gastropathy and gastric adaptation to ASA remains unclear. We compared gastric damage and adaptation after repeated exposures to ASA in the same subjects without H. pylori infection and those infected by H. pylori before and after eradication of this H. pylori. Twenty-four volunteers in two groups (A and B), without H. pylori infection (group A) and with H. pylori infection (group B) before and after H. pylori eradication, were given ASA 2 g/day or placebo for 14 days. Mucosal damage was evaluated by endoscopy and gastric microbleeding; mucosal prostaglandin (PG) E2 generation and luminal transforming growth factor (TGF)Î± were determined on days 0,3,7 and 14 of the ASA course. In all subjects, ASA-induced gastric damage reached a maximum on day 3. In H. pylori-positive subjects this damage was maintained at a similar level up to the 14th day of observation. Following H. pylori eradication, the damage was significantly lessened at day 14, as revealed by both endoscopy and microbleeding, and was accompanied by increased mucosal release of TGFÎ±. Prostaglandin E2 generation was significantly higher in H. pylori-positive subjects than after H. pylori eradication, but ASA treatment resulted in greater than 90% reduction of this generation independent of H. pylori status. Gastric adaptation to ASA is impaired in H. pylori-positive subjects but eradication of this bacterium restores this process.'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ int(q[0]['MedlineCitation']['PMID']) : str(q[0]['MedlineCitation']['Article']['Abstract']['AbstractText'][0]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the ids in our dataset refer to books from the [NCBI Bookshelf](http://www.ncbi.nlm.nih.gov/books/), a collection of freely available, downloadable, on-line versions of selected biomedical books. For such ids, `Entrez.efetch()` returns a slightly different structure, where the keys `[u'BookDocument', u'PubmedBookData']` take the place of the `[u'MedlineCitation', u'PubmedData']` keys we saw above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assemble a dataset mapping paper ids to their abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Abstracts_file = 'data/' + search_term + '__Abstracts.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Abstracts of results: \n",
      "\n",
      "0...................\n",
      "10000...................\n",
      "20000...................\n",
      "30000...................\n",
      "40000......."
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "from collections import deque\n",
    "\n",
    "if os.path.exists( Abstracts_file ):\n",
    "    Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "else:\n",
    "    # `Abstracts` will be incrementally assembled, by performing multiple queries,\n",
    "    # each returning at most `retrieve_per_query` entries.\n",
    "    Abstracts = deque()\n",
    "    retrieve_per_query = 500\n",
    "    \n",
    "    print('Fetching Abstracts of results: ')\n",
    "    for start in range( 0, len(Ids), retrieve_per_query ):\n",
    "        if (start % 10000 == 0):\n",
    "            print('')\n",
    "            print(start, end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        \n",
    "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
    "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
    "        \n",
    "        # issue requests to the server, until we get the full amount of data we expect\n",
    "        while True:\n",
    "            try:\n",
    "                s = Entrez.read( Entrez.efetch(db=\"pubmed\", id=query_ids, retmode=\"xml\" ) )['PubmedArticle']\n",
    "            except http.client.IncompleteRead:\n",
    "                print('r', end='')\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        i = 0\n",
    "        for p in s:\n",
    "            abstr = ''\n",
    "            if 'MedlineCitation' in p:\n",
    "                pmid = p['MedlineCitation']['PMID']\n",
    "                if 'Abstract' in p['MedlineCitation']['Article']:\n",
    "                    abstr = p['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
    "            elif 'BookDocument' in p:\n",
    "                pmid = p['BookDocument']['PMID']\n",
    "                if 'Abstract' in p['BookDocument']:\n",
    "                    abstr = p['BookDocument']['Abstract']['AbstractText'][0]\n",
    "            else:\n",
    "                raise Exception('Unrecognized record type, for id %d (keys: %s)' % (Ids[start+i], str(p.keys())) )\n",
    "            \n",
    "            Abstracts.append( (int(pmid), str(abstr)) )\n",
    "            i += 1\n",
    "    \n",
    "    # Save Abstracts, as a dictionary indexed by Ids\n",
    "    Abstracts = dict( Abstracts )\n",
    "    \n",
    "    pickle.dump( Abstracts, bz2.BZ2File( Abstracts_file, 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one paper's abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The relationship between Helicobacter pylori infection and aspirin (ASA)-induced gastropathy and gastric adaptation to ASA remains unclear. We compared gastric damage and adaptation after repeated exposures to ASA in the same subjects without H. pylori infection and those infected by H. pylori before and after eradication of this H. pylori. Twenty-four volunteers in two groups (A and B), without H. pylori infection (group A) and with H. pylori infection (group B) before and after H. pylori eradication, were given ASA 2 g/day or placebo for 14 days. Mucosal damage was evaluated by endoscopy and gastric microbleeding; mucosal prostaglandin (PG) E2 generation and luminal transforming growth factor (TGF)Î± were determined on days 0,3,7 and 14 of the ASA course. In all subjects, ASA-induced gastric damage reached a maximum on day 3. In H. pylori-positive subjects this damage was maintained at a similar level up to the 14th day of observation. Following H. pylori eradication, the damage was significantly lessened at day 14, as revealed by both endoscopy and microbleeding, and was accompanied by increased mucosal release of TGFÎ±. Prostaglandin E2 generation was significantly higher in H. pylori-positive subjects than after H. pylori eradication, but ASA treatment resulted in greater than 90% reduction of this generation independent of H. pylori status. Gastric adaptation to ASA is impaired in H. pylori-positive subjects but eradication of this bacterium restores this process.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abstracts[28976678]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELink: Searching for related items in NCBI Entrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to obtain paper citations with Entrez, we will first assemble a small set of PubMed IDs, and then query for their citations.\n",
    "To that end, we search here for papers published in the PLoS ONE journal (as before, having also the word \"aspirin\" in either the title or abstract):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28968454', '28931015', '28910305', '28880908', '28863196', '28841657', '28813512', '28792522', '28715503', '28636624', '28542447', '28542316', '28493889', '28475584', '28472145', '28459825', '28453510', '28426793', '28403216', '28362840']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_search_term = search_term+'[TIAB] AND PLoS ONE[JOUR]'\n",
    "CA_ids = Entrez.read( Entrez.esearch( db=\"pubmed\", term=CA_search_term ) )['IdList']\n",
    "CA_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'28362840': ('Aspirin-triggered resolvin D1 attenuates PDGF-induced vascular smooth muscle cell migration via the cyclic adenosine monophosphate/protein kinase A (cAMP/PKA) pathway.',\n",
       "  ['Mottola G', 'Chatterjee A', 'Wu B', 'Chen M', 'Conte MS'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0174936'),\n",
       " '28403216': ('Efficacy and safety of aspirin in patients with peripheral vascular disease: An updated systematic review and meta-analysis of randomized controlled trials.',\n",
       "  ['Mahmoud AN', 'Elgendy AY', 'Rambarat C', 'Mahtta D', 'Elgendy IY', 'Bavry AA'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0175283'),\n",
       " '28426793': ('Prevalence of cardiovascular medication on secondary prevention after myocardial infarction in China between 1995-2015: A systematic review and meta-analysis.',\n",
       "  ['Zhao M', 'Klipstein-Grobusch K', 'Wang X', 'Reitsma JB', 'Zhao D', 'Grobbee DE', 'Graham I', 'Vaartjes I'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0175947'),\n",
       " '28453510': ('Is aspirin associated with diabetic retinopathy? The Singapore Epidemiology of Eye Disease (SEED) study.',\n",
       "  ['Shi Y', 'Tham YC', 'Cheung N', 'Chua J', 'Tan G', 'Mitchell P', 'Wang JJ', 'Cheung YB', 'Cheng CY', 'Wong TY'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0175966'),\n",
       " '28459825': ('Patterns of analgesic use to relieve tooth pain among residents in British Columbia, Canada.',\n",
       "  ['Moeller J', 'Farmer J', 'QuiÃ±onez C'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0176125'),\n",
       " '28472145': ('Preoperative aspirin use and acute kidney injury after cardiac surgery: A propensity-score matched observational study.',\n",
       "  ['Hur M', 'Koo CH', 'Lee HC', 'Park SK', 'Kim M', 'Kim WH', 'Kim JT', 'Bahk JH'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0177201'),\n",
       " '28475584': ('Duration of dual antiplatelet therapy in patients treated with percutaneous coronary intervention for coronary chronic total occlusion.',\n",
       "  ['Lee SH', 'Yang JH', 'Choi SH', 'Park TK', 'Jang WJ', 'Song YB', 'Hahn JY', 'Choi JH', 'Gwon HC'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0176737'),\n",
       " '28493889': ('Characterization of a novel antibiofilm effect of nitric oxide-releasing aspirin (NCX-4040) on Candida albicans isolates from denture stomatitis patients.',\n",
       "  ['Madariaga-Venegas F', 'FernÃ¡ndez-Soto R', 'Duarte LF', 'Suarez N', 'Delgadillo D', 'Jara JA', 'FernÃ¡ndez-Ramires R', 'UrzÃºa B', 'Molina-BerrÃ­os A'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0176755'),\n",
       " '28542316': ('Antithrombotic therapy of patients with atrial fibrillation discharged after major non-cardiac surgery. 1-year follow-up. Sub-analysis of PRAGUE 14 study.',\n",
       "  ['Ondrakova M', 'Motovska Z', 'Waldauf P', 'Knot J', 'Havluj L', 'Bittner L', 'Bartoska R', 'GÅ±rlich R', 'Krbec M', 'Dzupa V', 'Grill R', 'Widimsky P'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0177519'),\n",
       " '28542447': ('Exploratory plasma proteomic analysis in a randomized crossover trial of aspirin among healthy men and women.',\n",
       "  ['Wang X', 'Shojaie A', 'Zhang Y', 'Shelley D', 'Lampe PD', 'Levy L', 'Peters U', 'Potter JD', 'White E', 'Lampe JW'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0178444'),\n",
       " '28636624': ('Metabolically-healthy obesity is associated with higher prevalence of colorectal adenoma.',\n",
       "  ['Sinn DH', 'Min YW', 'Son HJ', 'Rhee PL', 'Paik SW', 'Hong SN', 'Gwak GY'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0179480'),\n",
       " '28715503': ('Effects of preoperative aspirin on perioperative platelet activation and dysfunction in patients undergoing off-pump coronary artery bypass graft surgery: A prospective randomized study.',\n",
       "  ['Lee J', 'Jung CW', 'Jeon Y', 'Kim TK', 'Cho YJ', 'Koo CH', 'Choi YH', 'Kim KB', 'Hwang HY', 'Kim HR', 'Park JY'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0180466'),\n",
       " '28792522': ('Biochemical characterization and anti-inflammatory properties of an isothiocyanate-enriched moringa (Moringa oleifera) seed extract.',\n",
       "  ['Jaja-Chimedza A', 'Graf BL', 'Simmler C', 'Kim Y', 'Kuhn P', 'Pauli GF', 'Raskin I'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0182658'),\n",
       " '28813512': ('Implementation of a comprehensive intervention for patients at high risk of cardiovascular disease in rural China: A pragmatic cluster randomized controlled trial.',\n",
       "  ['Wei X', 'Walley JD', 'Zhang Z', 'Zou G', 'Gong W', 'Deng S', 'Harries AD', 'Hicks JP', 'Chong MKC', 'Newell JN', 'Zhong J', 'Yu M'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0183169'),\n",
       " '28841657': ('A prediction model for advanced colorectal neoplasia in an asymptomatic screening population.',\n",
       "  ['Hong SN', 'Son HJ', 'Choi SK', 'Chang DK', 'Kim YH', 'Jung SH', 'Rhee PL'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0181040'),\n",
       " '28863196': ('Impact of INR monitoring, reversal agent use, heparin bridging, and anticoagulant interruption on rebleeding and thromboembolism in acute gastrointestinal bleeding.',\n",
       "  ['Nagata N', 'Sakurai T', 'Moriyasu S', 'Shimbo T', 'Okubo H', 'Watanabe K', 'Yokoi C', 'Yanase M', 'Akiyama J', 'Uemura N'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0183423'),\n",
       " '28880908': ('Prostacyclin, thromboxane and glomerular filtration rate are abnormal in sickle cell pregnancy.',\n",
       "  ['Obilade OA', 'Akanmu AS', 'Broughton Pipkin F', 'Afolabi BB'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0184345'),\n",
       " '28910305': ('Aspirin increases metabolism through germline signalling to extend the lifespan of Caenorhabditis elegans.',\n",
       "  ['Huang XB', 'Mu XH', 'Wan QL', 'He XM', 'Wu GS', 'Luo HR'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0184027'),\n",
       " '28931015': ('Short versus prolonged dual antiplatelet therapy (DAPT) duration after coronary stent implantation: A comparison between the DAPT study and 9 other trials evaluating DAPT duration.',\n",
       "  ['Toyota T', 'Shiomi H', 'Morimoto T', 'Natsuaki M', 'Kimura T'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0174502'),\n",
       " '28968454': ('Reduction of intracerebral hemorrhage in hemodialysis patients after reducing aspirin use: A quality-assurance observational study.',\n",
       "  ['Aoun M', 'Koubar SH', 'Antoun L', 'Tamim H', 'Makki M', 'Chelala D'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0185847')}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_summ = {\n",
    "    p['Id'] : ( p['Title'], p['AuthorList'], p['PubDate'][:4], p['FullJournalName'], p.get('DOI', '') )\n",
    "    for p in Entrez.read( Entrez.esummary(db=\"pubmed\", id=','.join( CA_ids )) )\n",
    "    }\n",
    "CA_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we restricted our search to papers in an open-access journal, you can then follow their DOIs to freely access their PDFs at the journal's website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now issue calls to `Entrez.elink()` using these PubMed IDs, to retrieve the IDs of papers that cite them.\n",
    "The database from which the IDs will be retrieved is [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/), a free digital database of full-text scientific literature in the biomedical and life sciences.\n",
    "\n",
    "A complete list of the kinds of links you can retrieve with `Entrez.elink()` can be found [here](http://eutils.ncbi.nlm.nih.gov/entrez/query/static/entrezlinks.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'LinkSetDb': [{'Link': [{'Id': '5602518'}], 'DbTo': 'pmc', 'LinkName': 'pubmed_pmc_refs'}], 'LinkSetDbHistory': [], 'IdList': ['28792522'], 'ERROR': [], 'DbFrom': 'pubmed'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_citing = {\n",
    "    id : Entrez.read( Entrez.elink(\n",
    "            cmd = \"neighbor\",               # ELink command mode: \"neighbor\", returns\n",
    "                                            #     a set of UIDs in `db` linked to the input UIDs in `dbfrom`.\n",
    "            dbfrom = \"pubmed\",              # Database containing the input UIDs: PubMed\n",
    "            db = \"pmc\",                     # Database from which to retrieve UIDs: PubMed Central\n",
    "            LinkName = \"pubmed_pmc_refs\",   # Name of the Entrez link to retrieve: \"pubmed_pmc_refs\", gets\n",
    "                                            #     \"Full-text articles in the PubMed Central Database that cite the current articles\"\n",
    "            from_uid = id                   # input UIDs\n",
    "            ) )\n",
    "    for id in CA_ids\n",
    "    }\n",
    "\n",
    "CA_citing['28792522']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have in `CA_citing[paper_id][0]['LinkSetDb'][0]['Link']` the list of papers citing `paper_id`. To get it as just a list of ids, we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5602518']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cits = [ l['Id'] for l in CA_citing['28792522'][0]['LinkSetDb'][0]['Link'] ]\n",
    "cits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, one more step is needed, as what we have now are PubMed Central IDs, and not PubMed IDs. Their conversion can be achieved through an additional call to `Entrez.elink()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'LinkSetDb': [{'Link': [{'Id': '28922365'}], 'DbTo': 'pubmed', 'LinkName': 'pmc_pubmed'}], 'LinkSetDbHistory': [], 'IdList': ['5602518'], 'ERROR': [], 'DbFrom': 'pmc'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cits_pm = Entrez.read( Entrez.elink( dbfrom=\"pmc\", db=\"pubmed\", LinkName=\"pmc_pubmed\", from_uid=\",\".join(cits)) )\n",
    "cits_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5602518': '28922365'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_map = { pmc_id : link['Id'] for (pmc_id,link) in zip(cits_pm[0]['IdList'], cits_pm[0]['LinkSetDb'][0]['Link']) }\n",
    "ids_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to check these papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'28922365': ('Isothiocyanate-enriched moringa seed extract alleviates ulcerative colitis symptoms in mice.',\n",
       "  ['Kim Y', 'Wu AG', 'Jaja-Chimedza A', 'Graf BL', 'Waterman C', 'Verzi MP', 'Raskin I'],\n",
       "  '2017',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0184709')}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{   p['Id'] : ( p['Title'], p['AuthorList'], p['PubDate'][:4], p['FullJournalName'], p.get('DOI', '') )\n",
    "    for p in Entrez.read( Entrez.esummary(db=\"pubmed\", id=','.join( ids_map.values() )) )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now seen all the steps required to assemble a dataset of citations to each of the papers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Citations_file = 'data/' + search_term + '__Citations.pkl.bz2'\n",
    "Citations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least one server query will be issued per paper in `Ids`. Because NCBI allows for at most 3 queries per second (see [here](http://biopython.org/DIST/docs/api/Bio.Entrez-pysrc.html#_open)), this dataset will take a long time to assemble. Should you need to interrupt it for some reason, or the connection fail at some point, it is safe to just rerun the cell below until all data is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0..........."
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "\n",
    "if Citations == [] and os.path.exists( Citations_file ):\n",
    "    Citations = pickle.load( bz2.BZ2File( Citations_file, 'rb' ) )\n",
    "\n",
    "if len(Citations) < len(Ids):\n",
    "    \n",
    "    i = len(Citations)\n",
    "    checkpoint = len(Ids) / 10 + 1      # save to hard drive at every 10% of Ids fetched\n",
    "    \n",
    "    for pm_id in Ids[i:]:               # either starts from index 0, or resumes from where we previously left off\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # query for papers archived in PubMed Central that cite the paper with PubMed ID `pm_id`\n",
    "                c = Entrez.read( Entrez.elink( dbfrom = \"pubmed\", db=\"pmc\", LinkName = \"pubmed_pmc_refs\", id=str(pm_id) ) )\n",
    "                \n",
    "                c = c[0]['LinkSetDb']\n",
    "                if len(c) == 0:\n",
    "                    # no citations found for the current paper\n",
    "                    c = []\n",
    "                else:\n",
    "                    c = [ l['Id'] for l in c[0]['Link'] ]\n",
    "                    \n",
    "                    # convert citations from PubMed Central IDs to PubMed IDs\n",
    "                    p = []\n",
    "                    retrieve_per_query = 500\n",
    "                    for start in range( 0, len(c), retrieve_per_query ):\n",
    "                        query_ids = ','.join( c[start : start+retrieve_per_query] )\n",
    "                        r = Entrez.read( Entrez.elink( dbfrom=\"pmc\", db=\"pubmed\", LinkName=\"pmc_pubmed\", from_uid=query_ids ) )\n",
    "                        # select the IDs. If no matching PubMed ID was found, [] is returned instead\n",
    "                        p.extend( [] if r[0]['LinkSetDb']==[] else [ int(link['Id']) for link in r[0]['LinkSetDb'][0]['Link'] ] )\n",
    "                    c = p\n",
    "            \n",
    "            except http.client.BadStatusLine:\n",
    "                # Presumably, the server closed the connection before sending a valid response. Retry until we have the data.\n",
    "                print('r')\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        Citations.append( (pm_id, c) )\n",
    "        if (i % 10000 == 0):\n",
    "            print('')\n",
    "            print(i, end='')\n",
    "        if (i % 100 == 0):\n",
    "            print('.', end='')\n",
    "        i += 1\n",
    "        \n",
    "        if i % checkpoint == 0:\n",
    "            print('\\tsaving at checkpoint', i)\n",
    "            pickle.dump( Citations, bz2.BZ2File( Citations_file, 'wb' ) )\n",
    "    \n",
    "    print('\\n done.')\n",
    "    \n",
    "    # Save Citations, as a dictionary indexed by Ids\n",
    "    Citations = dict( Citations )\n",
    "    \n",
    "    pickle.dump( Citations, bz2.BZ2File( Citations_file, 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that we have indeed obtained the data we expected, you can match the ids below, with the ids listed at the end of last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Citations[5602518]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we go from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above generates multiple local files, containing the datasets we'll be working with. Loading them into memory is a matter of just issuing a call like<br>\n",
    "``data = pickle.load( bz2.BZ2File( data_file, 'rb' ) )``.\n",
    "\n",
    "The Entrez module will therefore no longer be needed, unless you wish to extend your data processing with additional information retrieved from PubMed.\n",
    "\n",
    "Should you be interested in looking at alternative ways to handle the data, have a look at the [sqlite3](http://docs.python.org/3/library/sqlite3.html) module included in Python's standard library, or [Pandas](http://pandas.pydata.org/), the Python Data Analysis Library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
